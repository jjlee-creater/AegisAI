import torch
from transformers import (
    pipeline,
    AutoTokenizer,
    AutoModelForSeq2SeqLM
)
from peft import PeftModel
import time
import os

# â­ï¸ Vertex AI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import vertexai
from vertexai.generative_models import GenerativeModel

# --- 1. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ê²½ë¡œ ì„¤ì • ---
CLASSIFIER_MODEL = "mangsense/codebert_java"
FIXER_BASE_MODEL = "Salesforce/codet5-base"
FIXER_LORA_ADAPTER = "mangsense/codet5-base-clean-LoRA"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# --- 2. â­ï¸ Vertex AI ì„¤ì • ---
PROJECT_ID = "gen-lang-client-0539365210"
LOCATION = "us-central1"
GEMINI_MODEL_NAME = "gemini-2.0-flash-exp"

print(f"--- ğŸš€ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œì‘ (Using: {DEVICE}) ---")

# --- 3. [0/3] ğŸ’¬ ì„¤ëª…ê¸°(Vertex AI Gemini) ë¡œë“œ ---
gemini_model = None

# ì‹œë„í•  ëª¨ë¸ ëª©ë¡
MODEL_CANDIDATES = [
    "gemini-2.0-flash-exp",
    "gemini-1.5-flash",
    "gemini-1.5-pro",
]

try:
    print(f"\n[0/3] ğŸ’¬ Vertex AI ì¸ì¦ ë° ëª¨ë¸ ë¡œë“œ ì¤‘...")
    
    # Vertex AI ì´ˆê¸°í™”
    vertexai.init(project=PROJECT_ID, location=LOCATION)
    
    # ì—¬ëŸ¬ ëª¨ë¸ ì‹œë„
    for model_name in MODEL_CANDIDATES:
        try:
            print(f"   ğŸ”„ ì‹œë„: {model_name}...", end=" ")
            test_model = GenerativeModel(model_name)
            
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
            response = test_model.generate_content("Hi")
            
            # ì„±ê³µí•˜ë©´ ì €ì¥
            gemini_model = test_model
            GEMINI_MODEL_NAME = model_name
            print(f"âœ… ì„±ê³µ!")
            break
            
        except Exception as e:
            print(f"âŒ ì‹¤íŒ¨")
            continue
    
    if gemini_model:
        print(f"âœ… ì„¤ëª…ê¸°(Gemini) ë¡œë“œ ì™„ë£Œ! (Model: {GEMINI_MODEL_NAME}, Project: {PROJECT_ID})")
    else:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   [í•´ê²°ì±…] 1. gcloud auth application-default login ì‹¤í–‰")
        print(f"   [í•´ê²°ì±…] 2. {PROJECT_ID} í”„ë¡œì íŠ¸ì˜ 'Vertex AI API' í™œì„±í™” í™•ì¸")
    
except Exception as e:
    print(f"âŒ Vertex AI (Gemini) ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    print("   [í•´ê²°ì±…] 1. gcloud auth application-default login ì‹¤í–‰")
    print(f"   [í•´ê²°ì±…] 2. gcloud services enable aiplatform.googleapis.com --project={PROJECT_ID}")
    gemini_model = None

# --- 4. [1/3] ğŸ•µï¸ ë¶„ë¥˜ê¸° (CodeBERT) ë¡œë“œ ---
print(f"\n[1/3] ğŸ•µï¸ ë¶„ë¥˜ê¸° ë¡œë“œ ì¤‘: {CLASSIFIER_MODEL}")
try:
    classifier = pipeline(
        "text-classification",
        model=CLASSIFIER_MODEL,
        device=0 if DEVICE == "cuda" else -1
    )
    print(f"ë¶„ë¥˜ê¸° ë ˆì´ë¸” ë§µ: {classifier.model.config.id2label}")
    print(f"âœ… ë¶„ë¥˜ê¸° ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    print(f"âŒ ë¶„ë¥˜ê¸° ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit()

# --- 5. [2/3] ğŸ› ï¸ ìˆ˜ì •ê¸° (CodeT5 + LoRA) ë¡œë“œ ---
print(f"\n[2/3] ğŸ› ï¸ ìˆ˜ì •ê¸° ë¡œë“œ ì¤‘: {FIXER_BASE_MODEL} + {FIXER_LORA_ADAPTER}")
print(f"   ğŸ“¦ í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ LoRA ì–´ëŒ‘í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
try:
    base_model = AutoModelForSeq2SeqLM.from_pretrained(
        FIXER_BASE_MODEL,
        load_in_8bit=True,
        device_map="auto"
    )
    fixer_tokenizer = AutoTokenizer.from_pretrained(FIXER_BASE_MODEL)
    
    fixer_model = PeftModel.from_pretrained(
        base_model, 
        FIXER_LORA_ADAPTER,
    )
    fixer_model.eval()
    
    print(f"âœ… ìˆ˜ì •ê¸° ë¡œë“œ ì™„ë£Œ (HuggingFace: {FIXER_LORA_ADAPTER})\n")
except Exception as e:
    print(f"âŒ ìˆ˜ì •ê¸° ë¡œë“œ ì‹¤íŒ¨: {e}")
    print(f"   [í•´ê²°ì±…] 1. ëª¨ë¸ì´ publicì¸ì§€ í™•ì¸: {FIXER_LORA_ADAPTER}")
    print(f"   [í•´ê²°ì±…] 2. í•„ìš”ì‹œ HuggingFace í† í° ì„¤ì •: huggingface-cli login")
    exit()

# --- 6. â­ï¸ Gemini ì„¤ëª… í•¨ìˆ˜ ì •ì˜ ---
def explain_fix_with_gemini(vulnerable_code, fixed_code, max_retries=3):
    """
    Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì½”ë“œ ìˆ˜ì • ì‚¬í•­ì„ ìì—°ì–´ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
    """
    if not gemini_model:
        return "âš ï¸ Gemini ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ì„¤ëª…ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    prompt = f"""
ë‹¹ì‹ ì€ Java ë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ 'Before' ì½”ë“œì˜ ë³´ì•ˆ ì·¨ì•½ì ê³¼ 'After' ì½”ë“œê°€ ì´ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í–ˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì„¤ëª…ì€ í•œêµ­ì–´ë¡œ, ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš” (200ì ì´ë‚´).

## [Before] ì·¨ì•½í•œ ì½”ë“œ:
```java
{vulnerable_code.strip()}
```

## [After] ìˆ˜ì •ëœ ì½”ë“œ:
```java
{fixed_code.strip()}
```

## [ì„¤ëª…]:
"""
    
    print(f"--- 3. ğŸ’¬ Gemini API í˜¸ì¶œ (ëª¨ë¸: {GEMINI_MODEL_NAME}) ---")
    
    for attempt in range(max_retries):
        try:
            response = gemini_model.generate_content(
                prompt,
                generation_config={
                    "temperature": 0.3,
                    "top_p": 0.8,
                    "top_k": 40,
                    "max_output_tokens": 512,
                }
            )
            
            print(f"âœ… Gemini API í˜¸ì¶œ ì„±ê³µ!")
            return response.text
            
        except Exception as e:
            error_msg = str(e)
            print(f"âš ï¸ ì‹œë„ {attempt + 1}/{max_retries} ì‹¤íŒ¨: {error_msg[:100]}...")
            
            if "quota" in error_msg.lower() or "429" in error_msg:
                print("   ğŸ’¡ API í• ë‹¹ëŸ‰ ì´ˆê³¼. ì ì‹œ í›„ ì¬ì‹œë„...")
                time.sleep(5)
            elif attempt < max_retries - 1:
                time.sleep(2)
            else:
                return f"âŒ Gemini API í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨: {error_msg}"

# --- 7. ì „ì²´ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ ---
def vulnerability_fix_pipeline(code_snippet):
    print("\n" + "="*50)
    print("--- 1. ğŸ•µï¸ ì·¨ì•½ì  ë¶„ë¥˜ ì‹œì‘ ---")
    
    classification_result = classifier(code_snippet)[0]
    label = classification_result['label']
    score = classification_result['score']
    
    print(f"â–¶ï¸  ë¶„ë¥˜ ê²°ê³¼: {label} (ì‹ ë¢°ë„: {score:.2%})")
    
    if label == 'LABEL_0':
        print("--- âœ… ì½”ë“œê°€ ì•ˆì „í•©ë‹ˆë‹¤. ìˆ˜ì •ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤. ---")
        print("="*50 + "\n")
        return code_snippet, "ìˆ˜ì •ì´ í•„ìš” ì—†ëŠ” ì•ˆì „í•œ ì½”ë“œì…ë‹ˆë‹¤."
    
    else:
        print("--- 2. ğŸ› ï¸ ì½”ë“œ ìˆ˜ì • ì‹œì‘ (CodeT5 + LoRA) ---")
        
        task_prefix = "fix this vulnerable C/C++ function: "
        
        input_ids = fixer_tokenizer(
            task_prefix + code_snippet,
            return_tensors="pt",
            max_length=512,
            truncation=True
        ).input_ids.to(DEVICE)

        try:
            generated_ids = fixer_model.generate(
                input_ids=input_ids,
                max_length=512,
                num_beams=5,
                early_stopping=True
            )
            
            fixed_code = fixer_tokenizer.decode(
                generated_ids[0], 
                skip_special_tokens=True
            )
            
            print("--- âœ… ì½”ë“œ ìˆ˜ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ---")
            
            # Gemini ì„¤ëª… í˜¸ì¶œ
            explanation = explain_fix_with_gemini(code_snippet, fixed_code)
            
            print("="*50 + "\n")
            return fixed_code, explanation
        
        except Exception as e:
            print(f"âŒ ì½”ë“œ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None, f"ì½”ë“œ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# --- 8. ì˜ˆì œ 2ë²ˆ: Command Injection ---
command_injection_example = """
import java.io.*;

public class CommandInjectionVulnerable {
    public void pingHost(String userInput) {
        try {
            String command = "ping -c 4 " + userInput;
            Runtime.getRuntime().exec(command);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
"""

print("\n\n" + "="*70)
print("ğŸ” ì˜ˆì œ 2ë²ˆ: Command Injection ì·¨ì•½ì  í…ŒìŠ¤íŠ¸")
print("="*70)
print("\n--- ğŸ“„ ì›ë³¸ ì·¨ì•½í•œ ì½”ë“œ ---")
print(command_injection_example)
print("----------------------------\n")

# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
fixed_code, explanation = vulnerability_fix_pipeline(command_injection_example)

if fixed_code:
    print("\n" + "="*70)
    print("--- ğŸ›¡ï¸ ìˆ˜ì •ëœ ì½”ë“œ ---")
    print("="*70)
    print(fixed_code)
    print("="*70)

if explanation:
    print("\n--- ğŸ’¡ Geminiì˜ ì·¨ì•½ì  ì„¤ëª… ---")
    print(explanation)
    print("-"*70 + "\n")
